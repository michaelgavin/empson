% Generated by roxygen2 (4.1.0): do not edit by hand
% Please edit documentation in R/find_similar.R
\name{find_similar}
\alias{find_similar}
\title{Find similar terms}
\usage{
find_similar(mat, keyword, method = "para", sorted = T, exclude = T)
}
\description{
Finds similar terms according to one of three metrics. All three metrics
together describe the structure of the word in the vector space.
}
\section{Slots}{

\describe{
\item{\code{mat}}{A word-context matrix (format either matrix or \code{docMatrix}).}

\item{\code{keyword}}{The character string (word) you are interested in evaluating.}

\item{\code{method}}{A character string: 'para', 'syn' or 'sig'.}

\item{\code{sorted}}{Logical value. If TRUE, will return only the top ten most similar words.}

\item{\code{exclude}}{Logical value. If TRUE, results will not return the keyword.}
}}
\section{Methods}{

\describe{
   \item{Signature}{Find context words that co-occur with a keyword. The 'signature' is
                    the word-count over a concordance.}
   \item{Paradigmatic}{Find terms that share a similar signature. "Paradigmatic similarity"
                       means that words are deployed in similar contexts.}
   \item{Syntagmatic}{Find terms that appear near similar keywords. "Syntagmatic similarity"
                      means that words group together as contexts for other keywords.}
}

Each one of these kinds of similarity names different kinds of relationships. For different
kinds of words, the most \emph{synonymous} words may co-occur either syntagmatically or
paradigmatically. My general sense is that lower frequency terms are more likely to find
synonyms syntagmatically and that higher frequency terms are more likely to find synonyms
paradigmatically. However, \emph{frequency} here is really a placeholder for a
semantic structure that needs better clarification.

The ability to disambiguate different 'senses' of a term by clustering their context words
seems like a crucial first step toward better specifying the conceptual relations that
underpin the structure. For now, though, it could be that the use of computational analysis
of concepts is limited to creating objects for human interpretation. In which case,
the similarity relationships identified in this function are best observed using the
\code{\link{graph_context}} function.
}
\examples{
# For 10 most paradigmatically similar words
find_similar(mat = eebo, keyword = "rights")

#For 10 most syntagmatically similar words
find_similar(mat = eebo, keyword = "rights", method = "syn")

#For 10 most frequent context ('signature') words
find_similar(mat = eebo, keyword = "rights", method = "sig")

#For full vector of similarity scores of all words
find_similar(mat = eebo, keyword = "rights", method = "para", sorted = F, exclude = F)
}

